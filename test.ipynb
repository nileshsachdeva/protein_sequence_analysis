{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "813e8e3d-3476-4808-958e-360c9d2d14fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM workspace.raw.accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ac25fa6-1d05-4784-84d7-ebc60ffc90da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "\n",
    "# Define path and table variables\n",
    "volumes_path = \"/Volumes/workspace/raw/accession\"\n",
    "uc_table = \"workspace.raw.accession\"\n",
    "\n",
    "def ingest_accession_numbers():\n",
    "    try:\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        # Read all .txt files from the Volumes path\n",
    "        txt_files_df = spark.read.text(volumes_path + \"/*.txt\").withColumnRenamed(\"value\", \"id\")\n",
    "        txt_files_df = txt_files_df.dropDuplicates([\"id\"])\n",
    "\n",
    "        # Read current accession numbers from UC table\n",
    "        if spark.catalog.tableExists(uc_table):\n",
    "            existing_df = spark.table(uc_table)\n",
    "        else:\n",
    "            existing_df = spark.createDataFrame([], txt_files_df.schema)\n",
    "\n",
    "        # Find new accession numbers not already in the table\n",
    "        new_df = txt_files_df.join(existing_df, on=\"id\", how=\"left_anti\")\n",
    "\n",
    "        # Write only new accession numbers to the table, using append mode\n",
    "        new_df_count = new_df.count()\n",
    "        print(f\"New accession numbers found: {new_df_count}\")\n",
    "        if new_df_count > 0:\n",
    "            new_df.write.mode(\"append\").saveAsTable(uc_table)\n",
    "            print(f\"Successfully ingested {new_df_count} new accession numbers in {uc_table}\")\n",
    "        else:\n",
    "            print(f\"All accession numbers already exist in {uc_table}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to ingest accession numbers with Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a3e79a0-7860-4aae-a9c1-d432f9005094",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ingest_accession_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6de1e0a4-54dc-4ac7-91a6-5b2b5c2fdde4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM workspace.raw.accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b5d2493-f7e2-4d03-99dd-54faa4b994a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DELETE FROM workspace.raw.accession"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5918022010126135,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
